e<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Surbhi Madan</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">

<!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Surbhi Madan</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/Surbhi.jpeg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="CV/Surbhi_Madan_CV.pdf" target="_blank">CV</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Work Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research">Research Interest</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    
                    
                    
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
        
                </ul>
            </div>
        </nav>
      
        
<!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content" >
                    <br><br><h2 class="mb-0">
                        Surbhi
                        <span class="text-primary">Madan</span>
                    </h2>
                    <div class="subheading mb-3">
                        Department of Computer Science and Engineering, LASSI Lab, Indian Institute of Technology Ropar, Punjab-140001, India<br>
                        <!-- <a href="mailto:d_kumar@cs.iitr.ac.in">surbhi.19csz0011@iitrpr.ac.in</a> -->
                        Mail Id: surbhi.19csz0011@iitrpr.ac.in
                    </div>
                    <p align="justify" class="lead mb-3" >I am a postdoc fellow at <a href="https://www.nii.ac.jp/en/",target="_blank">National Institute of Informatics</a>, Tokyo, Japan with <a href="https://yamagishilab.jp/", target="_blank">Yamagishi Lab, NII Group</a>. I completed my Ph.D. at the Machine Vision Lab, <a href="https://www.iitrpr.ac.in/", target="_blank">Indian Institute of Technology Ropar,
India</a>, under the supervision of <a href ="https://research.monash.edu/en/persons/abhinav-dhall/", target="_blank">Prof. Abhinav Dhall</a> and <a href="https://www.ramsubramanian.net/", target="_blank">Prof. Ramanathan Subramanian</a>. Before joining Ph.D., I have completed my master’s degree 
                        from <a href="https://nith.ac.in/", target="_blank">National Institute of Technology, Hamirpur</a>.
                    My research focused on Affective Computing, Multimodal human behavior analysis leveraging audio, text, visual, and physiological signal modalities. Additionally, I gained industry experience at Samsung Research Institute Bangalore (SRI-B), where I worked on Vision-Language Models (VLMs).</p>
                        <!--<p class="lead mb-3" align="justify">I'm passionate about relating humans and computers and use that understanding to optimize people's well-being. I perceive humans as an assembly of fat-muscle-bone-water on the hardware level
                             and a bundle of impressions-sensations-emotions-thoughts-actions on the software level. We are made up of carbon (instead of silicon), have mind-brain-hormones 
                             (as opposed to OS-processor-current), and deploy physical-mental-emotional-psychological-mental-spiritual resources (instead of computational resources) in reaction to various situations.</p> -->
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/deepak-kumar-ph-d-38ab1347/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/deepakkumar-iitr/deepakkumar-iitr.github.io/tree/source"><i class="fab fa-github"></i></a>
                        <a class="social-icon" href="#!"><i class="fab fa-twitter"></i></a>
                        <a class="social-icon" href="#!"><i class="fab fa-facebook-f"></i></a>
                        <a class="social-icon" href="https://scholar.google.com/citations?user=hZhuLIwAAAAJ&hl=en", target="_blank"><i class="fab fa-google"></i></a>
                    </div>
               <!-- </div>
            </section>
            <hr class="m-0" />
            

            <section class="resume-section" id="news">
                <div class="resume-section-content"> -->
    <br><br><hr>    
        <h3 class="mb-3">🔥 News</h3>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Oct 2025: Our paper titled <b>CSGaze: Context-aware Social Gaze Prediction</b> is accepted for the publication in <b>ICVGIP 2025 </b> to be held at IIT Mandi from December 17.
                    </li>
                     <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Sep 2025: Awarded funding under Sythetiq Vision Japan to attend <b> IEEE International Joint Conference on Biometrics (IJCB)</b> 2025 at OSaka Japan. 
                    </li>
                    
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Oct 2025: Became a reviewer of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165369", target="_blank">IEEE Transactions of Affective Computing</a> Journal.
                    </li>
                    <!-- <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Aug 2025: Completed Six months <a href="https://drive.google.com/file/d/1rneNif-TZnM-ySW-ewXyNk4p7Lx8Dj-m/view?usp=sharing", target="_blank">Research Internship </a> at SAMSUNG Research Institute Bangalore (SRI-B), India.
                    </li> -->
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Aug 2025: Became a reviewer of <a href="https://deepfakes1m.github.io/2025", target="_blank">1M-Deepfakes Detection Challenge</a> of the 33<sup>rd</sup> ACM International Conference on Multimedia (MM 2025).
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        July 2025: Defended Ph.D. Dissertation successfully on 10 July 2025.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2025: Became a reviewer of <a href="https://acmmm2025.org/datasets/", target="_blank">Dataset Track</a> of the 33<sup>rd</sup> ACM International Conference on Multimedia (MM 2025).
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2025: Became a <a href="https://drive.google.com/file/d/1BaNCJdz7b6-nQLryMelBLPe8DSwVRu1w/view?usp=sharing", target="_blank">reviewer</a> of <a href="https://www.ngndai.mnnit.ac.in/", target="_blank">International Conference</a> on Next-Generation Networks amd Deployable Artificial Intelligence (NGNDAI-2025).
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        May 2025: Submitted Ph.D. Thesis entitled 'From Signals to Visuals: Multimodal Affect and Behavior Analysis' on 24 May 2025.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2025: Selected for Six months Research Internship at SAMSUNG Research Institute Bangalore (SRI-B), India.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2024: Received travel Grant to attend The Fifth Indian Symposium on Machine Learning (IndoML) hosted by the BITS Pilani Goa Campus from December 21-23, 2024.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2024: Became a <a href="https://drive.google.com/file/d/1GYG605UdKL1iZCrSZdVD4_UeeuzrdwyG/view?usp=sharing", target="_blank">reviewer</a> of the IEEE 6<sup>th</sup> International Conference on Computational Intelligence and Networks, CINE 2024.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Nov 2024: Became a reviewer of the IEEE Signal Processing Letters journal.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Aug 2024: A paper titled 'Towards Engagement Prediction: A Cross-Modality Dual-Pipeline Approach using Visual and Audio Features' got accepted at The 32<sup>nd</sup> ACM International Conference on Multimedia (MM'24) 28 Oct-01 Nov 2024, Melbourne, Australia.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Aug 2024: A paper titled 'Fusing Multimodal Streams for Improved Group Emotion Recognition in Videos' got accepted at the 27<sup>th</sup> International Conference on Pattern Recognition (ICPR 2024), Dec 01-05, 2024, Kolkata, INDIA.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2024: Finalist, <a href="https://drive.google.com/file/d/1qHvrVTGF25sVYHJKd5g7IDiE-3ENHoqa/view?usp=sharing", target="_blank">Qualcomm Innovation Fellowship 2024</a> for an innovative <a href="https://www.qualcomm.com/research/university-relations/innovation-fellowship/2024-india", target="_blank">research proposal</a>.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2024: A paper titled 'All Signals Point to Personality: A Dual-Pipeline LSTM-Attention and Symbolic Dynamics Framework for Predicting Personality Traits from Bioelectrical Signals' got accepted in the Elsevier Biomedical Signal Processing and Control Journal.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2024: Became a reviewer of the 9<sup>th</sup> International Conference on Computer Vision and Image Processing (CVIP 2024).
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        April 2024: A paper titled 'Neuro-Emotional Mapping of Human Emotions via EEG Signals' got accepted at the 18<sup>th</sup> IEEE International Conference on Automatic Face and Gesture Recognition
27-31 May 2024 SDKM, ITU Campus, Istanbul, Turkey.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Mar 2024: I spearheaded the "Syntax" team in the "Brain Responses to Emotional Avatars Challenge" during the 18<sup>th</sup> IEEE International Conference on Automatic Face and Gesture Recognition (FG 2024), and<a href="https://drive.google.com/file/d/1-31Fey09p_bt5tlP8hF_7x4SKe4skhzB/view?usp=sharing", target="_blank"> secured the 2nd position</a>.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Mar 2024: A paper titled 'Integrating Physiological Signals with Dynamical Attention Networks for Personality Trait Analysis' got accepted at the 33<sup>rd</sup> International Joint Conference on Neural Networks (IJCNN 2024) Pacifico Yokohama, Yokohama, Japan.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2024: Became a reviewer of the 33<sup>rd</sup> International Joint Conference on Neural Network (IJCNN) Conference 2024.
                    </li>
                     <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Jan 2024: Completed six months of <a href="https://drive.google.com/file/d/1eSHAfBzMzn6qS2vrsfm7e36Mp0mPvHbY/view?usp=sharing", target="_blank"> work-studentship </a> program at Deloitte US – India Offices.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2023: Played a role as a <a href="https://drive.google.com/file/d/1sXFIeJxL8UWV5bVGEABKG3eeYWeu99f3/view?usp=sharing", target="_blank">volunteer</a> at the 14<sup>th</sup> The Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) conference 2023 from 15 - 17 December at IIT Ropar, India.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        July 2023: Selected for a Six-months work-studentship program at Deloitte, India.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2022: A paper titled 'Speech-based Automatic Prediction of Interview Traits' got accepted at The 7<sup>th</sup> International Conference on Computer Vision and Image Processing (CVIP 2022), VNIT Nagpur, India.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2021: Started pursuing Ph.D. at <a href="https://balarsgroup.github.io//"/>Machine Vision and Machine Intelligence Lab</a>, <a href="https://www.iitr.ac.in/" />IIT Roorkee </a> advised by <a href="http://faculty.iitr.ac.in/~balarfma/"/>Prof. Balasubramanian Raman</a>. 
                    </li>
                </ul>
<br><br><hr>
<!--       Education     --> 
<!-- <div class="resume-section-content"> -->
            <h3 class="mb-3" id="education">Education</h3>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-1">
                <div class="flex-grow-1">
                <h3 class="mb-0">Indian Institute of Technology, Ropar, Punjab, India</h3>
                <div class="subheading mb-0">Ph.D.</div>
                <div>Computer Science and Engineering</div>
                <p>CGPA: 9.0   <br>
                <b>Supervisor:</b> <a href ="https://research.monash.edu/en/persons/abhinav-dhall/", target="_blank">Prof. Abhinav Dhall</a> and <a href="https://www.ramsubramanian.net/", target="_blank">Prof. Ramanathan Subramanian</a></p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">December 2019 - July 2025 </span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">National Institute of Technology, Hamirpur, Himachal Pradesh, India</h3>
                    <div class="subheading mb-0">M.Tech.</div>
                    <div>Computer Science and Engineering</div>
                    <p>CGPA: 8.89 <br>
                        <b>Supervisor:</b> <a href="https://portfolios.nith.ac.in/index.php?/nith/rajeev-kumar-", target="_blank">Prof. Rajeev Kumar    </a>
                    </p>
                </div>
            <div class="flex-shrink-0"><span class="text-primary">August 2014 - June 2016</span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Uttar Pradesh Technical University Lucknow, Uttar Pradesh, India</h3>
                    <div class="subheading mb-0">B.Tech.</div>
                    <div>Computer Science and Engineering</div>
                    <p>PERCENTAGE: 78.15</p>
                </div>
        <!-- <div class="flex-shrink-0"><span class="text-primary">August 2014 - June 2016</span></div>  -->
            </div>
<br><hr>
<!--      Work Experience      -->
           <h3 class="mb-2" id="experience">Work Experience</h3>
            <!----------------->     
          <!--   <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Work-studentship </h3>
                            <div class="subheading mb-1">Deloitte US-India Offices</div>
                            <!-- <p>sdbhdbdjja</p>  -->
                     <!--    </div> 
                        <div class="flex-shrink-0"><span class="text-primary">August 2023 - January 2024</span></div>
                    </div>
               -->
            <!---------------------->
            <div class="d-flex flex-column flex-md-row justify-content-between mb-2">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Project Researcher (PostDoc)</h3>
                        <div class="subheading mb-3">National Institute of Informatics (NII), Tokyo, Japan</div>
                        <!-- <p>Job description </p>  -->
                     </div>
                    <div class="flex-shrink-0"><span class="text-primary">Aug 2025 - Present</span></div> 
                </div>
            <!---------------------->
                    
            <div class="d-flex flex-column flex-md-row justify-content-between mb-2">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Assistant Professor</h3>
                        <div class="subheading mb-3">Teerthanker Mahaveer University, Moradabad, Uttar Pradesh, India</div>
                        <!-- <p>Job description </p>  -->
                     </div>
                    <div class="flex-shrink-0"><span class="text-primary">July 2016 - November 2019</span></div> 
                </div> 

<hr>

<!--   Research Interest  -->

<h3 class="mb-3" id="research">Research Interests</h3>
<ul class="fa-ul mb-0">
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Affective Computing and Cognitive Science
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Machine Learning, Deep Learning, and Computer Vision
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Multimodal Information Analysis
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Human Computer Interaction (HCI)
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Vision Language Models (VLMs)
    </li>
    
</ul>
<br><hr> 

<!------       Publications  ----->
<h3 class="mb-4" id="publications"><span>Publications</span></h3>
<h4 class="mb-4" id="Journal"><span>&#128221; Journal</span></h4>
                <table><tbody>
                    
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>1</b>.&nbsp;</td>
                        <td><img src="assets/img/PLOS.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Monika Gahalawat, Tanaya Guha, Roland Goecke, and Ramanathan Subramanian, "Explainable Human-centered Traits from Head Motion and Facial 
                            Expression Dynamics" PLOS ONE. <b>[SCI, Q1, IF=2.9]</b>
                            <br>					 
                        </td>
                      </tr>
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>2</b>.&nbsp;</td>
                        <td><img src="assets/img/TAFFC.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            Gulshan Sharma, <b>Surbhi Madan</b>, Maneesh Bilalpur, Abhinav Dhall, and Ramanathan Subramanian, "EEG-based Cognitive Load Estimation of Acoustic Attributes 
                            for Data Sonification" IEEE Transactions on Cognitive and Developmental Systems. <b>[SCI, Q1, IF=5.0]</b>
                            <br>					 
                        </td>
                      </tr>
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>3</b>.&nbsp;</td>
                        <td><img src="assets/img/EEG.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Rishabn Jain, Ramanathan Subramanian, and Abhinav Dhall, "Multiview Attention Fusion for Explainable Body Language Behavior Recognition" 
                            IEEE Transactions on Affective Computing. <b>[SCI, Q1, IF=9.6]</b>
                            <br>					 
                        </td>
                      </tr>
                </tbody></table>
<br>
<!-- <h4 class="mb-4" id="Conference"><span>Conferences</span></h4>  -->
  <h4 id="Conference"><span>📝 Conferences</span></h4>                  
                <table><tbody>
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>1</b>.&nbsp;</td>
                        <td><img src="assets/img/Social_Gaze.png" width="420" height="100"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Shreya Ghosh, Ramanathan Subramanian, Abhinav Dhall, and Tom Gedeon, "CSGaze: Context-aware Social Gaze Prediction", The 16th Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) 
                            Dec 17 - 20, 2025, IIT Mandi, Himachal Pradesh, India.
                            <b>[Accepted]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>2</b>.&nbsp;</td>
                        <td><img src="assets/img/GEMS.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            A. Kataria <b>Surbhi Madan</b>, Shreya Ghosh, Tom Gedeon, and Abhinav Dhall, "GEMS: group emotion profiling
                            through multimodal situational understanding", 35th IEEE International Workshop on Machine
                            Learning for Signal Processing (IEEE MLSP 2025) Aug 31 - Sep 3, 2025 , Istanbul, Turkey.
                            <b>[CORE B | ERA B]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>3</b>.&nbsp;</td>
                        <td><img src="assets/img/MIP.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Shreya Ghosh, Lownish Rai Sookha Sookha, Mudasir Ahmad Ganaie, Ramanathan Subramanian, Abhinav Dhall, and Tom Gedeon, "MIP-
                            GAF: A MLLM-annotated Benchmark for Most Important Person Localization and Group Context
                            Understanding", Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
                            Vision (WACV 2025), Feb 28 – Mar 4, 2025, Tucson, Arizona.
                            <b>[CORE A | Qualis B1]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>4</b>.&nbsp;</td>
                        <td><img src="assets/img/MM.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            Deepak Kumar, <b>Surbhi Madan</b>, Pradeep Singh, Abhinav Dhall, and Balasubramanian Raman, "Towards Engagement Prediction: A Cross-Modality Dual-Pipeline Approach using Visual and Audio Features", 32nd ACM International Conference on Multimedia (MM'24) 28 Oct-01 Nov 2024, Melbourne, Australia.
                            <b>[CORE A* | ERA A]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>5</b>.&nbsp;</td>
                        <td><img src="assets/img/MAGIC.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Rishabh Jain, Gulshan Sharma, Ramanathan Subramanian, and Abhinav Dhall, "MAGIC-TBR: Multiview Attention Fusion 
                            for Transformer-based Bodily Behavior Recognition in Group Setting", Proceedings
                            of the 31st ACM International Conference on Multimedia (MM’23), pp. 9526-9530, October 29 -
                            November 3, 2023, Ottawa, Canada.
                            <b>[CORE A* | ERA A]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>6</b>.&nbsp;</td>
                        <td><img src="assets/img/HEAD.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Monika Gahalawat, Tanaya Guha, and Ramanathan Subramanian, "Head matters: explainable human-
                            centered trait prediction from head motion dynamics", Proceedings of the 23rd ACM International
                            Conference on Multimodal Interaction (ICMI 2021), pp. 435-443, October 18-22, 2021, Montreal, Canada.
                            <b>[CORE B | Qualis A2]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->

                      <tr valign="top">
                        <td style="vertical-align:top;"><b>7</b>.&nbsp;</td>
                        <td><img src="assets/img/SMART.jpg" width="420" height="300"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Deepak Kumar, and Anamika Agnihotri. "Privacy-Preserving Data Aggregation in Wireless Sensor." 2018 International Conference on System Modeling & Advancement in Research Trends (SMART 2018). 
                            <br>					 
                        </td>
                        
                      </tr>
                      &nbsp;
                      <!-- <tr valign="top">
                        <td style="vertical-align:top;"><b>7</b>.&nbsp;</td>
                        <td><img src="assets/img/CVIP_Final.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Deepak Kumar</b> and Balasubramanian Raman. "Speech-based Automatic Prediction of Interview Traits." 2018 International Conference on System Modeling & Advancement in Research Trends (SMART 2018). <b>[IAPR Endorsed ]</b>
                            <br>					 
                        </td>
                      </tr> -->
                    </tbody></table>
<br>
<hr>

<!--  Achievements  -->
<h3 class="mb-3">Achievements</h3>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Qualified GATE Computer Science in 2013, 2014.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Qualified UGC-NET (Computer Science) in Dec 2018.
                    </li>
                    
                </ul>
<br><hr>

<!-- Professional Membership   -->
<h3 class="mb-3">Professional Membership</h3>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Student member of IEEE (Institute of Electrical and Electronics Engineers)
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Professional member of ACM (Association for Computing Machinery)
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Associate member of IEI ( The Institution of Engineers (India) )
                    </li>
                </ul>
<br><hr>
<!-- </div> -->
<!-- Contact-->
<h3 class="mb-3" id="contact">Contact</h3>
                <p> <br>Yamagishi Lab <br> National Institute of Informatics 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430
 <br> Mail ID: surbhi.19csz0011@iitrpr.ac.in</p>

        </div>  
        </section>
        <hr class="m-0" />



        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
